1. Define HiveContext 
   import org.apache.spark.sql.hive._
   val hc = new HiveContext(sc)
   
2. Move to the database
   hc.sql("use flights")
   hc.sql("show tables").show
   
3. Read Flights and Planes dataFrame
   val flightsDF= hc.table("flights")
   val planesDF = hc.table("planes2")  

4. Sort the flights dataframe using distance to find the longest flight, do a take to look at the
   distance of the longest flight  
  
   Check the dataframesflightsDF.select($"FlightNum",$"Distance").order(Desc($"Distance").show(5)
   flightsDF.show(5) 
   planesDF.show(5)   
   planesDF.select("tailnum").count()
 
5. Register the tables
 
   flightsDF.registerTempTable("flights")
   planesDF.registerTempTable("planes")   
   
6. Test queries
   hc.sql("select * from planes limit 10").show
   hc.sql("select * from flights limit 10").show
   
 
6. Filter all flights on the longest flight distance, and return the tail numbers of those flights

   hc.sql("select TailNum from flights order by distance desc limit 10").show 
   
7. Join the tailnums to the planes RDD to get the models of the airplanes

   hc.sql("select model from flights inner join planes on (flights.tailnum=planes.tailnum)").show

8. Perform a count to find the most common airplane models

   hc.sql("select model,count(1) from planes group by model").show